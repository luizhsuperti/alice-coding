{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import collections\n",
    "\n",
    "#time packages\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /Users/luiz.superti/Documents/GitHub/alice-coding/cc_cid_calculator\n"
     ]
    }
   ],
   "source": [
    "from setup import main as setup\n",
    "setup(env='vscode', project='cc_cid_calculator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import StaggDiD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['member_internal_code', 'calendar_date', 'mth_order', 'total_n_mth',\n",
       "       'current_sex', 'current_gender', 'member_age', 'current_city',\n",
       "       'current_state', 'is_b2b', 'is_pitaya', 'diseases_sev', 'tds_cost',\n",
       "       'internacao_proced_cost', 'exam_cost', 'consulta_cost', 'er_cost',\n",
       "       'alice_therapy_cost', 'other_costs', 'total_care_cost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('src/data/cid_care_cost_did_calc_df.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diseases_'] = df['diseases_sev'].str.split(';')\n",
    "df2 = df.explode('diseases_')\n",
    "df2['cid_'] = df2['diseases_'].apply(lambda x: str(x).strip()[0:3])\n",
    "df3 = df2[['member_internal_code','calendar_date', 'cid_']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_internal_code</th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>cid_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC1000Z</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NC1000Z</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC1000Z</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114409</th>\n",
       "      <td>NC1ZZWN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>R74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114410</th>\n",
       "      <td>NC1ZZWN</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>R74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114411</th>\n",
       "      <td>NC1ZZWN</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>R74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114412</th>\n",
       "      <td>NC1ZZWN</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>N17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114412</th>\n",
       "      <td>NC1ZZWN</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>R74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       member_internal_code calendar_date cid_\n",
       "0                   NC1000Z    2022-05-31  nan\n",
       "1                   NC1000Z    2022-06-30  nan\n",
       "2                   NC1000Z    2022-07-31  nan\n",
       "3                   NC1002P    2021-12-31  nan\n",
       "4                   NC1002P    2022-01-31  nan\n",
       "...                     ...           ...  ...\n",
       "114409              NC1ZZWN    2022-05-31  R74\n",
       "114410              NC1ZZWN    2022-06-30  R74\n",
       "114411              NC1ZZWN    2022-07-31  R74\n",
       "114412              NC1ZZWN    2022-08-31  N17\n",
       "114412              NC1ZZWN    2022-08-31  R74\n",
       "\n",
       "[294508 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row = pd.get_dummies(df3['cid_'], prefix = 'cid')\n",
    "df_row_2 = df3[['member_internal_code', 'calendar_date']].merge(df_row, how = 'inner', left_index=True, right_index=True)\n",
    "df_row_3 = df_row_2.groupby(['member_internal_code', 'calendar_date']).max().reset_index()\n",
    "df_row_3.sort_values(by=['member_internal_code', 'calendar_date'], inplace=True)\n",
    "#create a cid filter\n",
    "df_row_3.drop(columns = 'cid_nan', inplace = True)\n",
    "cids_cols = [col for col in df_row_3 if col.startswith('cid_')]\n",
    "df_row_3[cids_cols] = df_row_3[cids_cols].apply(pd.to_numeric).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df.merge(\n",
    "                    pd.get_dummies(df.current_state, prefix = 'uf'),how = 'inner', left_index=True, right_index=True).merge(\n",
    "                        pd.get_dummies(df.current_city, prefix = 'city'),how = 'inner', left_index=True, right_index=True).drop(columns=['current_state', 'current_city'])\n",
    "df_filled['is_male'] = np.where(df_filled['current_sex']=='MALE',1,0)\n",
    "df_filled['is_trans'] = np.where(df_filled['current_sex']!=df_filled['current_gender'],1,0)\n",
    "#create the base-dummies\n",
    "df_filled.drop(columns=['current_gender','current_sex','city_São Paulo', 'uf_SP',\n",
    "                        'diseases_sev','tds_cost', 'exam_cost', 'consulta_cost',\n",
    "                        'internacao_proced_cost', 'er_cost',\n",
    "                        'alice_therapy_cost', 'other_costs'], inplace=True)\n",
    "df_filled.drop(columns=['diseases_'], inplace=True)\n",
    "\n",
    "base_covariates_list = df_filled.drop(columns = ['member_internal_code', 'calendar_date', 'mth_order','total_n_mth', 'total_care_cost']).columns.to_list()\n",
    "core_covariates = ['member_age', 'is_pitaya', 'is_male']\n",
    "#y = ['total_care_cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_internal_code</th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>mth_order</th>\n",
       "      <th>total_n_mth</th>\n",
       "      <th>member_age</th>\n",
       "      <th>is_b2b</th>\n",
       "      <th>is_pitaya</th>\n",
       "      <th>total_care_cost</th>\n",
       "      <th>uf_AC</th>\n",
       "      <th>uf_AL</th>\n",
       "      <th>...</th>\n",
       "      <th>cid_Z91</th>\n",
       "      <th>cid_Z92</th>\n",
       "      <th>cid_Z93</th>\n",
       "      <th>cid_Z95</th>\n",
       "      <th>cid_Z96</th>\n",
       "      <th>cid_Z97</th>\n",
       "      <th>cid_Z98</th>\n",
       "      <th>n_total_cids</th>\n",
       "      <th>ref_mth</th>\n",
       "      <th>ref_mth_entrance_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC1000Z</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NC1000Z</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>629</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC1000Z</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.019120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107.373738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>625</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>626</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>627</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>677.768498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>628</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NC1002P</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.079314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>629</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  member_internal_code calendar_date  mth_order  total_n_mth  member_age  \\\n",
       "0              NC1000Z    2022-05-31          1            3        33.0   \n",
       "1              NC1000Z    2022-06-30          2            3        33.0   \n",
       "2              NC1000Z    2022-07-31          3            3        34.0   \n",
       "3              NC1002P    2021-12-31          1            9        26.0   \n",
       "4              NC1002P    2022-01-31          2            9        26.0   \n",
       "5              NC1002P    2022-02-28          3            9        26.0   \n",
       "6              NC1002P    2022-03-31          4            9        26.0   \n",
       "7              NC1002P    2022-04-30          5            9        26.0   \n",
       "8              NC1002P    2022-05-31          6            9        26.0   \n",
       "9              NC1002P    2022-06-30          7            9        26.0   \n",
       "\n",
       "   is_b2b  is_pitaya  total_care_cost  uf_AC  uf_AL  ...  cid_Z91  cid_Z92  \\\n",
       "0       0          0         0.000000      0      0  ...        0        0   \n",
       "1       0          0         0.000000      0      0  ...        0        0   \n",
       "2       0          0        16.019120      0      0  ...        0        0   \n",
       "3       1          0         0.000000      0      0  ...        0        0   \n",
       "4       1          0       107.373738      0      0  ...        0        0   \n",
       "5       1          0         0.000000      0      0  ...        0        0   \n",
       "6       1          0        18.990966      0      0  ...        0        0   \n",
       "7       1          0         0.000000      0      0  ...        0        0   \n",
       "8       1          0       677.768498      0      0  ...        0        0   \n",
       "9       1          0       140.079314      0      0  ...        0        0   \n",
       "\n",
       "   cid_Z93  cid_Z95  cid_Z96  cid_Z97  cid_Z98  n_total_cids  ref_mth  \\\n",
       "0        0        0        0        0        0             0      628   \n",
       "1        0        0        0        0        0             0      629   \n",
       "2        0        0        0        0        0             0      630   \n",
       "3        0        0        0        0        0             0      623   \n",
       "4        0        0        0        0        0             0      624   \n",
       "5        0        0        0        0        0             0      625   \n",
       "6        0        0        0        0        0             0      626   \n",
       "7        0        0        0        0        0             0      627   \n",
       "8        0        0        0        0        0             1      628   \n",
       "9        0        0        0        0        0             2      629   \n",
       "\n",
       "   ref_mth_entrance_group  \n",
       "0                     628  \n",
       "1                     628  \n",
       "2                     628  \n",
       "3                     623  \n",
       "4                     623  \n",
       "5                     623  \n",
       "6                     623  \n",
       "7                     623  \n",
       "8                     623  \n",
       "9                     623  \n",
       "\n",
       "[10 rows x 1607 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = df_filled.merge(df_row_3, how = 'inner', left_on=['member_internal_code', 'calendar_date'], right_on = ['member_internal_code', 'calendar_date'])\n",
    "\n",
    "#adjust variables\n",
    "ml_df['n_total_cids'] = ml_df[cids_cols].sum(axis=1)\n",
    "ml_df['ref_mth'] = (pd.to_datetime(ml_df['calendar_date']).dt.to_period('M') -   pd.to_datetime(['1970-01-31']).to_period('M')).apply(lambda x: x.n)\n",
    "\n",
    "#entry-calendar date\n",
    "ml_df['v1'] = np.where(ml_df['mth_order']==1, ml_df['ref_mth'], np.nan)\n",
    "ml_df = ml_df.merge(ml_df.groupby(['member_internal_code'])['v1'].min().rename('ref_mth_entrance_group'), how = 'inner', left_on = 'member_internal_code', right_index = True)\n",
    "ml_df['ref_mth_entrance_group'] = ml_df['ref_mth_entrance_group'].astype('Int64')\n",
    "ml_df.drop(columns = ['v1'], inplace = True)\n",
    "ml_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df_calendar_base = ml_df[['member_internal_code','calendar_date','mth_order','ref_mth', 'ref_mth_entrance_group']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accountable_cids = ml_df.groupby('member_internal_code')[cids_cols].min().drop_duplicates().sum(axis=0).sort_values(ascending=False)\n",
    "accountable_cids = accountable_cids[accountable_cids>=10].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# define pipeline 1\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "# define pipeline 1\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "dd = StaggDiD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current cid: entry_cid_H52\n",
      "dataframe creation pt1\n",
      "Propensity score matching w/ SMOTE and resampling\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/luiz.superti/Documents/GitHub/alice-coding/cc_cid_calculator/notebooks/main.ipynb Celda 19\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luiz.superti/Documents/GitHub/alice-coding/cc_cid_calculator/notebooks/main.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m y \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mmth_order\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m][entry_name]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luiz.superti/Documents/GitHub/alice-coding/cc_cid_calculator/notebooks/main.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPropensity score matching w/ SMOTE and resampling\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luiz.superti/Documents/GitHub/alice-coding/cc_cid_calculator/notebooks/main.ipynb#X23sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m X, y \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit_resample(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luiz.superti/Documents/GitHub/alice-coding/cc_cid_calculator/notebooks/main.ipynb#X23sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m clf \u001b[39m=\u001b[39m logit\u001b[39m.\u001b[39mfit(X,y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luiz.superti/Documents/GitHub/alice-coding/cc_cid_calculator/notebooks/main.ipynb#X23sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m pre_treat \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(df[df[\u001b[39m'\u001b[39m\u001b[39mmth_order\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m][base_covariates_list \u001b[39m+\u001b[39m cid_list])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imblearn/pipeline.py:346\u001b[0m, in \u001b[0;36mPipeline.fit_resample\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m\"\"\"Fit the model and sample with the final estimator.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39mFits all the transformers/samplers one after the other and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m    Transformed target.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 346\u001b[0m Xt, yt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    347\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    348\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imblearn/pipeline.py:226\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m     X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    217\u001b[0m         cloned_transformer,\n\u001b[1;32m    218\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    225\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(cloned_transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_resample\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 226\u001b[0m     X, y, fitted_transformer \u001b[39m=\u001b[39m fit_resample_one_cached(\n\u001b[1;32m    227\u001b[0m         cloned_transformer,\n\u001b[1;32m    228\u001b[0m         X,\n\u001b[1;32m    229\u001b[0m         y,\n\u001b[1;32m    230\u001b[0m         message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    231\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    232\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imblearn/pipeline.py:394\u001b[0m, in \u001b[0;36m_fit_resample_one\u001b[0;34m(sampler, X, y, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_resample_one\u001b[39m(sampler, X, y, message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m    393\u001b[0m     \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m--> 394\u001b[0m         X_res, y_res \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49mfit_resample(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    396\u001b[0m         \u001b[39mreturn\u001b[39;00m X_res, y_res, sampler\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imblearn/base.py:79\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     76\u001b[0m arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m     77\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampling_strategy, y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampling_type\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resample(X, y)\n\u001b[1;32m     85\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[1;32m     86\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[1;32m     87\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imblearn/utils/_validation.py:534\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[39mif\u001b[39;00m sampling_strategy \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m sampling_strategy \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    528\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    529\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWhen \u001b[39m\u001b[39m'\u001b[39m\u001b[39msampling_strategy\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is a float, it should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39min the range (0, 1]. Got \u001b[39m\u001b[39m{\u001b[39;00msampling_strategy\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m         )\n\u001b[1;32m    532\u001b[0m     \u001b[39mreturn\u001b[39;00m OrderedDict(\n\u001b[1;32m    533\u001b[0m         \u001b[39msorted\u001b[39m(\n\u001b[0;32m--> 534\u001b[0m             _sampling_strategy_float(sampling_strategy, y, sampling_type)\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    535\u001b[0m         )\n\u001b[1;32m    536\u001b[0m     )\n\u001b[1;32m    537\u001b[0m \u001b[39melif\u001b[39;00m callable(sampling_strategy):\n\u001b[1;32m    538\u001b[0m     sampling_strategy_ \u001b[39m=\u001b[39m sampling_strategy(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/imblearn/utils/_validation.py:373\u001b[0m, in \u001b[0;36m_sampling_strategy_float\u001b[0;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[1;32m    367\u001b[0m     sampling_strategy_ \u001b[39m=\u001b[39m {\n\u001b[1;32m    368\u001b[0m         key: \u001b[39mint\u001b[39m(n_sample_majority \u001b[39m*\u001b[39m sampling_strategy \u001b[39m-\u001b[39m value)\n\u001b[1;32m    369\u001b[0m         \u001b[39mfor\u001b[39;00m (key, value) \u001b[39min\u001b[39;00m target_stats\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    370\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m class_majority\n\u001b[1;32m    371\u001b[0m     }\n\u001b[1;32m    372\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m([n_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m n_samples \u001b[39min\u001b[39;00m sampling_strategy_\u001b[39m.\u001b[39mvalues()]):\n\u001b[0;32m--> 373\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    374\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe specified ratio required to remove samples \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfrom the minority class while trying to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgenerate new samples. Please increase the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mratio.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    378\u001b[0m         )\n\u001b[1;32m    379\u001b[0m \u001b[39melif\u001b[39;00m sampling_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39munder-sampling\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    380\u001b[0m     n_sample_minority \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(target_stats\u001b[39m.\u001b[39mvalues())\n",
      "\u001b[0;31mValueError\u001b[0m: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio."
     ]
    }
   ],
   "source": [
    "entry_list_cids = []\n",
    "diagnosed_list  = []\n",
    "results_df = pd.DataFrame()\n",
    "for cid in accountable_cids:\n",
    "    #cid_list not including the cid\n",
    "    cid_list = [c for c in cids_cols if c!=cid]\n",
    "\n",
    "    temp_df = pd.concat([ml_df_calendar_base, ml_df[cid]], axis = 1)\n",
    "    temp_df.sort_values(by = ['member_internal_code', 'calendar_date'], inplace = True)\n",
    "    #\n",
    "    lag_name = cid + '_lag_1'\n",
    "    temp_df = pd.concat([temp_df,temp_df.groupby(['member_internal_code'])[cid].shift(1).rename(lag_name)], axis = 1)\n",
    "    temp_df.sort_values(by = ['member_internal_code', 'calendar_date'], inplace = True)\n",
    "    #\n",
    "    entry_name = 'entry_' + cid\n",
    "    diag_name = 'diag_' + cid\n",
    "    #\n",
    "    temp_df['v1'] = np.where((temp_df[cid]==1) & (temp_df['mth_order']==1), 1, 0)\n",
    "    temp_df['ind_diag_mth'] = np.where((temp_df[cid]==1) & (temp_df[lag_name]!=1) & (temp_df['mth_order']>=2), 1, 0)\n",
    "    temp_df = temp_df.merge(temp_df.groupby(['member_internal_code'])['v1'].max().rename(entry_name), how = 'inner', left_on = 'member_internal_code', right_index = True)\n",
    "    temp_df = temp_df.merge(temp_df.groupby(['member_internal_code'])['ind_diag_mth'].max().rename(diag_name), how = 'inner', left_on = 'member_internal_code', right_index = True)\n",
    "    temp_df.drop(columns = ['v1',lag_name], inplace = True)\n",
    "\n",
    "    if temp_df[entry_name].mean()>0:\n",
    "        print('current cid:', entry_name)\n",
    "        #DF to estimate variables\n",
    "        print('dataframe creation pt1')\n",
    "\n",
    "        treat_group_mths = temp_df[temp_df[entry_name]==1]['ref_mth_entrance_group'].unique()\n",
    "        control_group = temp_df[(temp_df['ref_mth_entrance_group'].isin(treat_group_mths)) & (temp_df[entry_name]==0) & (temp_df[entry_name]==0)]\n",
    "        total_df = pd.concat([temp_df[temp_df[entry_name]==1], control_group], axis = 0)\n",
    "        df = ml_df[base_covariates_list + cid_list + ['total_care_cost'] + ['member_internal_code','mth_order', 'ref_mth_entrance_group']].merge(total_df[[entry_name] + ['ind_diag_mth']], how = 'inner', left_index = True, right_index = True)\n",
    "        df = df.merge(df[df['ind_diag_mth']==1].groupby('member_internal_code')['mth_order'].max().rename('diag_mth_order'), how = 'left', left_on = 'member_internal_code', right_index = True)\n",
    "\n",
    "        X = df[df['mth_order']==1][base_covariates_list + cid_list]\n",
    "        y = df[df['mth_order']==1][entry_name]\n",
    "\n",
    "        print('Propensity score matching w/ SMOTE and resampling')\n",
    "        X, y = pipeline.fit_resample(X, y)\n",
    "\n",
    "        clf = logit.fit(X,y)\n",
    "        pre_treat = clf.predict(df[df['mth_order']==1][base_covariates_list + cid_list])\n",
    "\n",
    "        print('dataframe creation pt2')\n",
    "        df.loc[df['mth_order']==1, 'pre_treat'] = pre_treat\n",
    "        df = df.merge(df.groupby(['member_internal_code'])['pre_treat'].max().rename('pre_treat_max'), how = 'inner', left_on = 'member_internal_code', right_index = True)\n",
    "        df['treat'] = np.where(df[entry_name]==1, 1, 0)\n",
    "        df.loc[(df['treat']==0) & (df['pre_treat_max']==0), 'treat'] = np.nan\n",
    "\n",
    "        month_list = df[df[entry_name]==1]['ref_mth_entrance_group'].unique()\n",
    "        ml_df = df[df['ref_mth_entrance_group'].isin(month_list) & (df['treat'].notna())][['member_internal_code','mth_order','ref_mth_entrance_group','ind_diag_mth','diag_mth_order','treat', 'total_care_cost'] + core_covariates]\n",
    "        print('dataframe creation pt3: event analysis')\n",
    "        df = pd.DataFrame()\n",
    "        for pr_mth in ml_df['ref_mth_entrance_group'].unique():\n",
    "            diag_months = ml_df[(ml_df['ind_diag_mth']==1) & (ml_df['ref_mth_entrance_group']==pr_mth)]['diag_mth_order'].unique()\n",
    "            print(pr_mth, diag_months)\n",
    "            for mth in diag_months:\n",
    "                treat_df = ml_df[(ml_df['ref_mth_entrance_group']==pr_mth) & (ml_df['treat']==1) & (ml_df['diag_mth_order']==mth)]\n",
    "                treat_df['ev_an_mth'] = treat_df['mth_order'] - mth\n",
    "                treat_df = treat_df.merge(treat_df.groupby('member_internal_code')['mth_order'].min().rename('min_mth_order'),how = 'inner', left_on='member_internal_code', right_index = True)\n",
    "                treat_df = treat_df.merge(treat_df.groupby('member_internal_code')['ev_an_mth'].min().rename('min_ev_an_mth'),how = 'inner', left_on='member_internal_code', right_index = True)\n",
    "                treat_df['id_group'] = treat_df['member_internal_code'].astype(str) + '_' + treat_df['min_ev_an_mth'].astype(str) + '_' + treat_df['min_mth_order'].astype(str)        \n",
    "                treat_df.drop(columns = ['min_mth_order', 'min_ev_an_mth'], inplace = True)\n",
    "                #\n",
    "                control_df = ml_df[(ml_df['ref_mth_entrance_group']==pr_mth) & (ml_df['treat']==0)]\n",
    "                control_df['ev_an_mth'] = control_df['mth_order'] - mth\n",
    "                control_df = control_df.merge(control_df.groupby('member_internal_code')['mth_order'].min().rename('min_mth_order'),how = 'inner', left_on='member_internal_code', right_index = True)\n",
    "                control_df = control_df.merge(control_df.groupby('member_internal_code')['ev_an_mth'].min().rename('min_ev_an_mth'),how = 'inner', left_on='member_internal_code', right_index = True)\n",
    "                control_df['id_group'] = control_df['member_internal_code'].astype(str) + '_' + control_df['min_ev_an_mth'].astype(str) + '_' + control_df['min_mth_order'].astype(str)\n",
    "                control_df.drop(columns = ['min_mth_order', 'min_ev_an_mth'], inplace = True)\n",
    "\n",
    "                df = pd.concat([df,treat_df, control_df], axis = 0)\n",
    "\n",
    "        final_ml_df = df.sort_values(['id_group','ev_an_mth'])\n",
    "        final_ml_df.drop(columns = ['mth_order', 'diag_mth_order', 'ind_diag_mth', 'member_internal_code'], inplace = True)    \n",
    "        print('att_calculus')\n",
    "        att_df = dd.att(final_ml_df, 'id_group', 'treat', 'total_care_cost', 'ev_an_mth', -3, 7)\n",
    "\n",
    "        att_df['cid'] = cid\n",
    "        att_df['analysis_type'] = 'at_entry' \n",
    "        results_df = pd.concat([results_df, att_df], axis = 0)\n",
    "        entry_list_cids.append(entry_name)\n",
    "\n",
    "    if temp_df[diag_name].mean()>0:\n",
    "        print('current cid:', diag_name)\n",
    "        diagnosed_list.append(diag_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11139401654996817"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for  entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treat_group_mths = temp_df[temp_df[diag_name]==1]['ref_mth_entrance_group'].unique()\n",
    "control_group = temp_df[(temp_df['ref_mth_entrance_group'].isin(treat_group_mths)) & (temp_df[diag_name]==0) & (temp_df[diag_name]==0)]\n",
    "total_df = pd.concat([temp_df[temp_df[diag_name]==1], control_group], axis = 0)\n",
    "df = ml_df[base_covariates_list + cid_list + y + ['member_internal_code','mth_order', 'ref_mth_entrance_group']].merge(total_df[[diag_name] + ['ind_diag_mth']], how = 'inner', left_index = True, right_index = True)\n",
    "df = df.merge(df[df['ind_diag_mth']==1].groupby('member_internal_code')['mth_order'].max().rename('diag_mth_order'), how = 'left', left_on = 'member_internal_code', right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ml_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = StaggDiD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ml_df[(final_ml_df['ev_an_mth'] == -1) & (final_ml_df['treat'] == 1)][['member_internal_code','total_care_cost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ml_df[(final_ml_df['ev_an_mth'] == -3) & (final_ml_df['treat'] == 1)][['member_internal_code','total_care_cost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = final_ml_df[(final_ml_df['ev_an_mth'] == -1) & (final_ml_df['treat'] == 0)][['member_internal_code','total_care_cost']].merge(final_ml_df[(final_ml_df['ev_an_mth'] == -1) & (final_ml_df['treat'] == 1)][['member_internal_code','total_care_cost']], how = 'inner', on = 'member_internal_code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ml_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ml_df[(final_ml_df['ev_an_mth'] == -1) & (final_ml_df['treat'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ml_df[(final_ml_df['ev_an_mth'] == -1) & (final_ml_df['treat'] == 1)][['member_internal_code','total_care_cost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean_treat = np.mean(final_ml_df[(final_ml_df[time] == -3) & (final_ml_df['treat'] == 1)]['total_care_cost'] - final_ml_df[(df[time] == -1) & (df[treatment] == 1)][outcome]);\n",
    "len_treat = len(df[(df[time] == t) & (df[treatment] == 1)][outcome] - df[(df[time] == -1) & (df[treatment] == 1)][outcome]);\n",
    "            temp_var_treat = np.var(df[(df[time] == t) & (df[treatment] == 1)][outcome] - df[(df[time] == -1) & (df[treatment] == 1)][outcome]);\n",
    "            temp_mean_control = np.mean(df[(df[time] == t) & (df[treatment] == 0)][outcome] - df[(df[time] == -1) & (df[treatment] == 0)][outcome]);\n",
    "            len_control = len(df[(df[time] == t) & (df[treatment] == 1)][outcome] - df[(df[time] == -1) & (df[treatment] == 1)][outcome]);\n",
    "            temp_var_control = np.var(df[(df[time] == t) & (df[treatment] == 0)][outcome] - df[(df[time] == -1) & (df[treatment] == 0)][outcome]);   \n",
    "            \n",
    "            temp_att_dist = [(temp_var_treat - temp_mean_control), (temp_var_treat/len_treat + temp_var_control/len_control)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df.to_csv('src/data/panel_cc_cids_did_df.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
